{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d98e2db-8519-4cd8-9f75-9e65331585a1",
   "metadata": {},
   "source": [
    "# Notebook ICD - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bea34-06dd-4b57-90da-dce66eeedabf",
   "metadata": {},
   "source": [
    "Install libraries via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582ef0ff-9295-4337-89ee-764fe81c0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy\n",
    "#pip install nltk\n",
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a1956-9666-48c5-98a5-2cbb514c22ef",
   "metadata": {},
   "source": [
    "Importing necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce4c060-b967-4856-b7cf-b6ea32740ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 11:58:04.604647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy as spc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d0bc4-caab-43b2-b791-7a903f2a67f6",
   "metadata": {},
   "source": [
    "## Datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f38d8f-f3e8-4bae-8afe-b74fd140ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\n"
     ]
    }
   ],
   "source": [
    "oracion = \"@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\"\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace6213-b9e5-4dde-80f8-cffede8fc3b7",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72533121-a276-4248-9cd1-71bfdc4ce66f",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afad44f-9233-4584-9e43-5cad07ef213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n"
     ]
    }
   ],
   "source": [
    "oracion = oracion.lower()\n",
    "oracion = re.sub(r\"@\\S+\", \"\", oracion)  # Eliminar menciones a usuarios\n",
    "oracion = re.sub(\"http[s]?\\://\\S+\", \"\", oracion)  # Eliminar enlaces\n",
    "oracion = re.sub(r\"#\\S+\", \"\", oracion)  # Eliminar hashtags\n",
    "oracion = re.sub(r\"[0-9]\", \"\", oracion)  # Eliminar números\n",
    "oracion = re.sub(r\"(\\(.*\\))|(\\[.*\\])\", \"\", oracion)  # Eliminar paréntesis y corchetes\n",
    "oracion = re.sub(r\"\\n\", \"\", oracion)  # Eliminar caracteres de nueva línea\n",
    "oracion = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\", oracion)  # Eliminar varios patrones\n",
    "oracion = re.sub(r\"(\\.)|(,)\", \"\", oracion)  # Eliminar puntos y comas\n",
    "oracion = re.sub(r\"[¡!]\", \"\", oracion)  # Eliminar signos de admiración \n",
    "oracion = re.sub(r\"[¿?]\", \"\", oracion)  # Eliminar signos de exclamación\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20449-7603-4d01-9866-6be0fbf0063c",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a798d9-a52d-41bf-80b6-4d36808cee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estoy', 'buscando', 'un', 'producto', 'genial', 'por', 'menos', 'de', 'he', 'encontrado', 'muchos', 'en', 'qué', 'opinas', 'quiero', 'comprarlo', 'ya']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "tokens = word_tokenize(oracion)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33108d-855f-4898-a16d-82d8fd19ee4f",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9990057-f614-463c-bc59-276163f9c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buscando', 'producto', 'genial', 'menos', 'encontrado', 'opinas', 'quiero', 'comprarlo']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "palabras_filtradas = [palabra for palabra in tokens if palabra not in spanish_stopwords]\n",
    "print(palabras_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd83dce-3bb0-4258-a752-3297c1fffa55",
   "metadata": {},
   "source": [
    "### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9854623a-2f73-46ec-8f1d-8cd14e31d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo python3 -m spacy download es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a78c030-5094-48a0-aa9c-dc63ff9bfddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buscar producto genial menos encontrado opina querer comprar él\n"
     ]
    }
   ],
   "source": [
    "nlp = spc.load(\"es_core_news_sm\")\n",
    "lema = nlp(\" \".join(palabras_filtradas))\n",
    "oracion_lematizada = \" \".join([token.lemma_ for token in lema])\n",
    "print(oracion_lematizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d08ba-3bff-4982-8a0d-53e1b16209f4",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2736fdd5-dde2-48d7-ad8d-01d1db87f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = CountVectorizer()\n",
    "vectores = vectorizador.fit_transform([oracion_lematizada])\n",
    "vocabulario = vectorizador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c90384-68b0-460a-8cd3-82becb828de8",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71ef6ab-76b1-4e20-adbb-5dd1c25e1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración de entrada:  estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n",
      "Oración lematizada: buscar producto genial menos encontrado opina querer comprar él\n",
      "Vectores Bag of Words: [[1 1 1 1 1 1 1 1 1]]\n",
      "Vocabulario: ['buscar' 'comprar' 'encontrado' 'genial' 'menos' 'opina' 'producto'\n",
      " 'querer' 'él']\n"
     ]
    }
   ],
   "source": [
    "print(\"Oración de entrada:\", oracion)\n",
    "print(\"Oración lematizada:\", oracion_lematizada)\n",
    "print(\"Vectores Bag of Words:\", vectores.toarray())\n",
    "print(\"Vocabulario:\", vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b9bcd-1d1c-443b-b06a-8551bdee0af7",
   "metadata": {},
   "source": [
    "### Construir Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c552894-bc08-4397-8982-3cb8df82052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buscar</th>\n",
       "      <th>comprar</th>\n",
       "      <th>encontrado</th>\n",
       "      <th>genial</th>\n",
       "      <th>menos</th>\n",
       "      <th>opina</th>\n",
       "      <th>producto</th>\n",
       "      <th>querer</th>\n",
       "      <th>él</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buscar  comprar  encontrado  genial  menos  opina  producto  querer  él\n",
       "0       1        1           1       1      1      1         1       1   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bw = pd.DataFrame.sparse.from_spmatrix(vectores,columns = vocabulario)\n",
    "df_bw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae042ce-df3f-4b1e-8f6d-306c9c621703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
