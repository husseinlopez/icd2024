{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8ce271-f93d-46d7-8067-c23c0f660b3e",
   "metadata": {},
   "source": [
    "# Notebook ICD - 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ca965-8251-4fcf-93d9-b8146faa84c3",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a811cb-3656-4291-b411-639931679b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1587950-f7f0-4e94-89e8-52063ca53351",
   "metadata": {},
   "source": [
    "## Perceptron from scratch\n",
    "\n",
    "The Perceptron is a foundational algorithm in ML, representing one of the simplest forms of neural networks. It is a type of linear classifier used for binary classification tasks, where it determines the decision boundary based on a linear combination of input features. The main steps in the Perceptron algorithm include:\n",
    "\n",
    "Initialization: The algorithm begins by initializing weights (including the bias term) to zero or small random values. These weights correspond to the influence each feature has on the final classification.\n",
    "\n",
    "Prediction: For each input, the Perceptron computes a weighted sum of the features and adds a bias. This result is then passed through a step function (the activation function), where it outputs 1 if the result is greater than or equal to zero, and 0 otherwise.\n",
    "\n",
    "Training and Weight Update: During training, the Perceptron iteratively updates its weights based on the difference between the predicted output and the actual target. If the prediction is incorrect, the weights are adjusted to reduce future errors for that specific example. This process repeats over multiple iterations (epochs) until the algorithm converges (i.e., when all examples are classified correctly or the maximum number of iterations is reached).\n",
    "\n",
    "Limitations: A key limitation of the Perceptron algorithm is that it can only solve linearly separable problems. For datasets that are not linearly separable, the algorithm will not converge, leading to suboptimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9434849d-fb30-474d-ace2-ca4775cb4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
    "        # Initialize the learning rate and the number of iterations (epochs)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights to zero, including the bias term (w0)\n",
    "        self.weights = np.zeros(X.shape[1] + 1)\n",
    "        ###print(f\"Initial weights (iteration 0): {self.weights}\")\n",
    "        \n",
    "        # Iteratively adjust weights based on prediction error\n",
    "        for iteration in range(self.n_iterations):\n",
    "            for xi, target in zip(X, y):\n",
    "                # Predict the output for the current example\n",
    "                prediction = self.predict(xi)\n",
    "                \n",
    "                # Update weights if the prediction is incorrect\n",
    "                update = self.learning_rate * (target - prediction)\n",
    "                self.weights[1:] += update * xi  # Update weights for features\n",
    "                self.weights[0] += update        # Update bias term\n",
    "            \n",
    "            # Print weights at the end of each iteration\n",
    "            ###print(f\"Weights after iteration {iteration + 1}/{self.n_iterations}: {self.weights}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Compute the weighted sum of inputs and add the bias term\n",
    "        weighted_sum = np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "        \n",
    "        # Activation function: returns 1 if weighted sum is >= 0, else 0\n",
    "        return 1 if weighted_sum >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94f21f-b246-4a9e-aaf6-e3adc2118e9f",
   "metadata": {},
   "source": [
    "### Implementation example\n",
    "\n",
    "This example demonstrates how to use the Perceptron model to classify instances from the \"weather\" dataset, which determines if playing tennis is advisable based on weather conditions. The process includes data preprocessing, defining feature and target sets, and training the Perceptron model.\n",
    "\n",
    "Data Preprocessing: The original dataset contains categorical features (e.g., \"outlook,\" \"temperature,\" etc.) that need to be converted to numerical values for the Perceptron algorithm. We use a simple encoding method to map each categorical value to a unique integer.\n",
    "\n",
    "Defining Features and Labels: After preprocessing, the features (X) include all columns except the target label (\"play\"), which indicates whether playing tennis is recommended. The target (y) consists of binary values where 1 represents \"yes\" and 0 represents \"no.\"\n",
    "\n",
    "Training the Perceptron: With preprocessed data, we initialize a Perceptron instance and train it on the feature and target sets. The model iteratively adjusts its weights based on prediction errors, eventually learning a decision boundary that separates the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3776662d-25e4-4286-8ad2-34e6c9b654ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather dataset\n",
    "data = pd.read_csv('weather.nominal.csv')\n",
    "\n",
    "# Data Preprocessing: Convert categorical features to numerical codes\n",
    "# This step maps each unique categorical value to an integer, preparing the data for the Perceptron\n",
    "data['outlook'] = data['outlook'].map({'sunny': 0, 'overcast': 1, 'rainy': 2})\n",
    "data['temperature'] = data['temperature'].map({'hot': 0, 'mild': 1, 'cool': 2})\n",
    "data['humidity'] = data['humidity'].map({'high': 0, 'normal': 1})\n",
    "data['windy'] = data['windy'].map({False: 0, True: 1})\n",
    "data['play'] = data['play'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "# X includes all columns except the last one, which is the target\n",
    "X = data.iloc[:, :-1].values  # All columns except the last one (features)\n",
    "y = data.iloc[:, -1].values   # Last column only (target label)\n",
    "\n",
    "# Train the Perceptron model with the weather data\n",
    "# Create a Perceptron instance with a learning rate of 0.1 and 100 iterations\n",
    "perceptron = Perceptron(learning_rate=0.1, n_iterations=100)\n",
    "perceptron.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21efbb2-f17f-4ed1-aedb-a6f4d030f37e",
   "metadata": {},
   "source": [
    "A new weather condition to test if the trained Perceptron model correctly predicts whether to play tennis is created. The new example represents specific weather features (e.g., sunny outlook, mild temperature, high humidity, weak wind). Based on these input conditions, the model predicts \"Yes\" or \"No\" for playing tennis.\n",
    "\n",
    "New Example: The array nuevo_ejemplo encodes the weather features into integers matching the preprocessing mapping used during training.\n",
    "Prediction: We pass this array to the predict method of the trained Perceptron model.\n",
    "Result Output: Based on the model’s output (1 for \"Yes,\" 0 for \"No\"), we print an interpretable result to confirm if playing tennis is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba903af-a8f2-450a-86aa-be89bcc166b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Jugar tenis con las condiciones [2 1 0 0]? No\n"
     ]
    }
   ],
   "source": [
    "# Prueba con un nuevo ejemplo (Clima='soleado', Temperatura='templado', Humedad='alta', Viento='débil')\n",
    "nuevo_ejemplo = np.array([2, 1, 0, 0])\n",
    "resultado = perceptron.predict(nuevo_ejemplo)\n",
    "\n",
    "# Resultado de la predicción\n",
    "print(f\"¿Jugar tenis con las condiciones {nuevo_ejemplo}? {'Sí' if resultado == 1 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351c58c-53a3-48be-a1ed-2e9a25039b97",
   "metadata": {},
   "source": [
    "## Perceptron using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a8aa8a-ce8e-40fa-a4dd-bd1bf5c84ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   Outlook  Temperature  Humidity    Wind   Play\n",
      "0     1     sunny           85        85    weak  False\n",
      "1     2     sunny           80        90  strong  False\n",
      "2     3  overcast           83        86    weak   True\n",
      "3     4      rain           70        96    weak   True\n",
      "4     5      rain           68        80    weak   True\n",
      "5     6      rain           65        70  strong  False\n",
      "6     7  overcast           64        65  strong   True\n",
      "7     8     sunny           72        95    weak  False\n",
      "8     9     sunny           69        70    weak   True\n",
      "9    10      rain           75        80    weak   True\n",
      "10   11     sunny           75        70  strong   True\n",
      "11   12  overcast           72        90  strong   True\n",
      "12   13  overcast           81        75    weak   True\n",
      "13   14      rain           71        91  strong  False\n",
      "    Outlook  Temperature  Humidity    Wind\n",
      "0     sunny           85        85    weak\n",
      "1     sunny           80        90  strong\n",
      "2  overcast           83        86    weak\n",
      "3      rain           70        96    weak\n",
      "4      rain           68        80    weak\n",
      "    Play\n",
      "0  False\n",
      "1  False\n",
      "2   True\n",
      "3   True\n",
      "4   True\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'weather.numeric.csv')\n",
    "print(df)\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "X_train = df[['Outlook', 'Temperature', 'Humidity', 'Wind']]\n",
    "y_train = df[['Play']]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159f0184-bbbc-43cd-8f08-6d45b80c0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity  Wind\n",
      "0         2           85        85     2\n",
      "1         2           80        90     2\n",
      "2         0           83        86     0\n",
      "3         1           70        96     1\n",
      "4         1           68        80     1\n",
      "5         1           65        70     1\n",
      "6         0           64        65     0\n",
      "7         2           72        95     2\n",
      "8         2           69        70     2\n",
      "9         1           75        80     1\n",
      "10        2           75        70     2\n",
      "11        0           72        90     0\n",
      "12        0           81        75     0\n",
      "13        1           71        91     1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "outlook = X_train.iloc[:,0]\n",
    "outlook_enc = encoder.fit_transform(outlook)\n",
    "wind = X_train.iloc[:,3]\n",
    "wind_enc = encoder.fit_transform(wind)\n",
    "\n",
    "df_outlook = pd.DataFrame(outlook_enc, columns = ['Outlook'])\n",
    "df_wind = pd.DataFrame(outlook_enc, columns = ['Wind'])\n",
    "X_train_num = pd.concat([df_outlook, X_train.iloc[:,1], X_train.iloc[:,2], df_wind], axis=1)\n",
    "print(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c1d52c-c7e8-430c-b382-cb07ad133ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_numes, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4575de70-31c0-4164-bb7b-642ddbbedb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Outlook  Temperature  Humidity  Wind\n",
      "0        2           60        65     1\n",
      "[False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but Perceptron was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# sunny:2, hot:85, normal:65, strong:0 \n",
    "new_example = [[2, 60, 65, 1]]\n",
    "X_test = pd.DataFrame(new_example, columns = ['Outlook', 'Temperature', 'Humidity', 'Wind'])\n",
    "print(X_test)\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4846ef-6b4d-4478-8c38-b44798d6853b",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron from scratch\n",
    "\n",
    "A Multilayer Perceptron (MLP) is a class of neural networks consisting of multiple layers: an input layer, one or more hidden layers, and an output layer. Each layer is fully connected to the next layer, enabling complex, nonlinear transformations. The MLP operates in two phases:\n",
    "\n",
    "- Forward Propagation: The input data passes through each layer, where weights and biases are applied, and an activation function (e.g., sigmoid) is used to introduce non-linearity. The output from one layer becomes the input to the next until the final output is produced.\n",
    "\n",
    "- Backpropagation and Weight Adjustment: The error is calculated between the network's output and the true target values. This error is backpropagated through the layers, and weights are updated based on the gradient of the loss function. The process uses the learning rate to control weight adjustments.\n",
    "\n",
    "The MLP code below demonstrates these principles, showing weight updates across iterations and printing the loss and accuracy at each step to monitor learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40551bd6-7a9c-4538-9ef3-8348e23b3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, learning_rate=0.1, epochs=1000):\n",
    "        # Initialize network parameters: input, hidden, and output layer sizes, learning rate, and training epochs\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_outputs = n_outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Initialize weights for input to hidden layer connections (including bias)\n",
    "        self.weights_input_hidden = np.random.rand(self.n_inputs + 1, self.n_hidden) * 0.1\n",
    "        \n",
    "        # Initialize weights for hidden to output layer connections (including bias)\n",
    "        self.weights_hidden_output = np.random.rand(self.n_hidden + 1, self.n_outputs) * 0.1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # Sigmoid activation function, used to introduce non-linearity\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # Derivative of the sigmoid function, required for backpropagation\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Add a bias column (ones) to the input data matrix X\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            errors = []  # List to record the error for each sample\n",
    "            predictions = []  # List to store predicted values for accuracy calculation\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                # Forward pass: compute hidden layer activations and final output\n",
    "                input_layer = X[i]\n",
    "                hidden_net = np.dot(input_layer, self.weights_input_hidden)\n",
    "                hidden_output = self.sigmoid(hidden_net)\n",
    "                \n",
    "                # Add bias to the hidden layer output\n",
    "                hidden_output = np.append(1, hidden_output)\n",
    "                \n",
    "                output_net = np.dot(hidden_output, self.weights_hidden_output)\n",
    "                final_output = self.sigmoid(output_net)\n",
    "                \n",
    "                # Calculate output error (target - prediction) and record squared error\n",
    "                output_error = y[i] - final_output\n",
    "                errors.append(output_error**2)\n",
    "                \n",
    "                # Store binary predictions (1 if >= 0.5, else 0) for accuracy\n",
    "                predictions.append(1 if final_output >= 0.5 else 0)\n",
    "                \n",
    "                # Backpropagation: calculate gradients and update weights\n",
    "                delta_output = output_error * self.sigmoid_derivative(final_output)\n",
    "                \n",
    "                # Calculate hidden layer error and gradient (excluding bias neuron)\n",
    "                hidden_error = delta_output.dot(self.weights_hidden_output[1:].T)\n",
    "                delta_hidden = hidden_error * self.sigmoid_derivative(hidden_output[1:])\n",
    "                \n",
    "                # Update weights for hidden to output layer\n",
    "                self.weights_hidden_output += self.learning_rate * np.outer(hidden_output, delta_output)\n",
    "                \n",
    "                # Update weights for input to hidden layer\n",
    "                self.weights_input_hidden += self.learning_rate * np.outer(input_layer, delta_hidden)\n",
    "            \n",
    "            # Calculate and print loss and accuracy for each epoch\n",
    "            loss = np.mean(errors)\n",
    "            accuracy = np.mean(np.equal(predictions, y))\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "     \n",
    "    def predict(self, X):\n",
    "        # Add bias to input data point\n",
    "        X = np.insert(X, 0, 1)\n",
    "        \n",
    "        # Forward pass: calculate hidden layer and output layer activations\n",
    "        hidden_net = np.dot(X, self.weights_input_hidden)\n",
    "        hidden_output = self.sigmoid(hidden_net)\n",
    "        \n",
    "        # Add bias to hidden layer output\n",
    "        hidden_output = np.insert(hidden_output, 0, 1)\n",
    "        \n",
    "        output_net = np.dot(hidden_output, self.weights_hidden_output)\n",
    "        final_output = self.sigmoid(output_net)\n",
    "        \n",
    "        return 1 if final_output >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39273c-375a-46ec-b644-952cd6e328fe",
   "metadata": {},
   "source": [
    "### Implementation example\n",
    "\n",
    "Previous MLP is implemented to classify weather conditions to determine whether playing tennis is advisable. First, the weather dataset is loaded and preprocessed to make it compatible with the MLP model. The dataset consists of categorical variables, which are converted to numerical values, as neural networks typically require numerical input data. Each category within variables such as outlook, temperature, humidity, and windy is mapped to a unique integer value. For instance, the outlook values of sunny, overcast, and rainy are represented by 0, 1, and 2, respectively. Similarly, the target variable play is encoded as 0 for \"no\" and 1 for \"yes.\" This encoding process enables the MLP model to process the input effectively during training.\n",
    "\n",
    "With the dataset prepared, the feature matrix X is defined to include all columns except the target label play, while y contains the target labels indicating the decision to play tennis (0 or 1) for each set of weather conditions. Next, the MLP model is initialized with specified parameters: 4 input neurons (one for each feature), 3 neurons in the hidden layer, and 1 output neuron for binary classification. The learning rate is set at 0.1, and the model is trained over 100 iterations, allowing it to learn from the dataset and refine its predictions.\n",
    "\n",
    "During training, the MLP’s fit function iterates over the dataset, updating weights by calculating the error between the predicted and actual outputs. This iterative process continues for the specified number of epochs, gradually minimizing the model’s prediction error. Through this adjustment, the MLP improves its capacity to make accurate predictions based on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0e8e30-0160-43c1-be09-5bf795f46eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 0.2411, Accuracy: 0.6429\n",
      "Epoch 2/100 - Loss: 0.2383, Accuracy: 0.6429\n",
      "Epoch 3/100 - Loss: 0.2364, Accuracy: 0.6429\n",
      "Epoch 4/100 - Loss: 0.2350, Accuracy: 0.6429\n",
      "Epoch 5/100 - Loss: 0.2339, Accuracy: 0.6429\n",
      "Epoch 6/100 - Loss: 0.2332, Accuracy: 0.6429\n",
      "Epoch 7/100 - Loss: 0.2327, Accuracy: 0.6429\n",
      "Epoch 8/100 - Loss: 0.2323, Accuracy: 0.6429\n",
      "Epoch 9/100 - Loss: 0.2320, Accuracy: 0.6429\n",
      "Epoch 10/100 - Loss: 0.2318, Accuracy: 0.6429\n",
      "Epoch 11/100 - Loss: 0.2317, Accuracy: 0.6429\n",
      "Epoch 12/100 - Loss: 0.2315, Accuracy: 0.6429\n",
      "Epoch 13/100 - Loss: 0.2314, Accuracy: 0.6429\n",
      "Epoch 14/100 - Loss: 0.2314, Accuracy: 0.6429\n",
      "Epoch 15/100 - Loss: 0.2313, Accuracy: 0.6429\n",
      "Epoch 16/100 - Loss: 0.2313, Accuracy: 0.6429\n",
      "Epoch 17/100 - Loss: 0.2312, Accuracy: 0.6429\n",
      "Epoch 18/100 - Loss: 0.2312, Accuracy: 0.6429\n",
      "Epoch 19/100 - Loss: 0.2312, Accuracy: 0.6429\n",
      "Epoch 20/100 - Loss: 0.2311, Accuracy: 0.6429\n",
      "Epoch 21/100 - Loss: 0.2311, Accuracy: 0.6429\n",
      "Epoch 22/100 - Loss: 0.2311, Accuracy: 0.6429\n",
      "Epoch 23/100 - Loss: 0.2311, Accuracy: 0.6429\n",
      "Epoch 24/100 - Loss: 0.2310, Accuracy: 0.6429\n",
      "Epoch 25/100 - Loss: 0.2310, Accuracy: 0.6429\n",
      "Epoch 26/100 - Loss: 0.2310, Accuracy: 0.6429\n",
      "Epoch 27/100 - Loss: 0.2310, Accuracy: 0.6429\n",
      "Epoch 28/100 - Loss: 0.2309, Accuracy: 0.6429\n",
      "Epoch 29/100 - Loss: 0.2309, Accuracy: 0.6429\n",
      "Epoch 30/100 - Loss: 0.2309, Accuracy: 0.6429\n",
      "Epoch 31/100 - Loss: 0.2309, Accuracy: 0.6429\n",
      "Epoch 32/100 - Loss: 0.2308, Accuracy: 0.6429\n",
      "Epoch 33/100 - Loss: 0.2308, Accuracy: 0.6429\n",
      "Epoch 34/100 - Loss: 0.2308, Accuracy: 0.6429\n",
      "Epoch 35/100 - Loss: 0.2308, Accuracy: 0.6429\n",
      "Epoch 36/100 - Loss: 0.2307, Accuracy: 0.6429\n",
      "Epoch 37/100 - Loss: 0.2307, Accuracy: 0.6429\n",
      "Epoch 38/100 - Loss: 0.2307, Accuracy: 0.6429\n",
      "Epoch 39/100 - Loss: 0.2307, Accuracy: 0.6429\n",
      "Epoch 40/100 - Loss: 0.2306, Accuracy: 0.6429\n",
      "Epoch 41/100 - Loss: 0.2306, Accuracy: 0.6429\n",
      "Epoch 42/100 - Loss: 0.2306, Accuracy: 0.6429\n",
      "Epoch 43/100 - Loss: 0.2305, Accuracy: 0.6429\n",
      "Epoch 44/100 - Loss: 0.2305, Accuracy: 0.6429\n",
      "Epoch 45/100 - Loss: 0.2305, Accuracy: 0.6429\n",
      "Epoch 46/100 - Loss: 0.2305, Accuracy: 0.6429\n",
      "Epoch 47/100 - Loss: 0.2304, Accuracy: 0.6429\n",
      "Epoch 48/100 - Loss: 0.2304, Accuracy: 0.6429\n",
      "Epoch 49/100 - Loss: 0.2304, Accuracy: 0.6429\n",
      "Epoch 50/100 - Loss: 0.2303, Accuracy: 0.6429\n",
      "Epoch 51/100 - Loss: 0.2303, Accuracy: 0.6429\n",
      "Epoch 52/100 - Loss: 0.2303, Accuracy: 0.6429\n",
      "Epoch 53/100 - Loss: 0.2302, Accuracy: 0.6429\n",
      "Epoch 54/100 - Loss: 0.2302, Accuracy: 0.6429\n",
      "Epoch 55/100 - Loss: 0.2302, Accuracy: 0.6429\n",
      "Epoch 56/100 - Loss: 0.2301, Accuracy: 0.6429\n",
      "Epoch 57/100 - Loss: 0.2301, Accuracy: 0.6429\n",
      "Epoch 58/100 - Loss: 0.2301, Accuracy: 0.6429\n",
      "Epoch 59/100 - Loss: 0.2300, Accuracy: 0.6429\n",
      "Epoch 60/100 - Loss: 0.2300, Accuracy: 0.6429\n",
      "Epoch 61/100 - Loss: 0.2300, Accuracy: 0.6429\n",
      "Epoch 62/100 - Loss: 0.2299, Accuracy: 0.6429\n",
      "Epoch 63/100 - Loss: 0.2299, Accuracy: 0.6429\n",
      "Epoch 64/100 - Loss: 0.2299, Accuracy: 0.6429\n",
      "Epoch 65/100 - Loss: 0.2298, Accuracy: 0.6429\n",
      "Epoch 66/100 - Loss: 0.2298, Accuracy: 0.6429\n",
      "Epoch 67/100 - Loss: 0.2297, Accuracy: 0.6429\n",
      "Epoch 68/100 - Loss: 0.2297, Accuracy: 0.6429\n",
      "Epoch 69/100 - Loss: 0.2297, Accuracy: 0.6429\n",
      "Epoch 70/100 - Loss: 0.2296, Accuracy: 0.6429\n",
      "Epoch 71/100 - Loss: 0.2296, Accuracy: 0.6429\n",
      "Epoch 72/100 - Loss: 0.2296, Accuracy: 0.6429\n",
      "Epoch 73/100 - Loss: 0.2295, Accuracy: 0.6429\n",
      "Epoch 74/100 - Loss: 0.2295, Accuracy: 0.6429\n",
      "Epoch 75/100 - Loss: 0.2294, Accuracy: 0.6429\n",
      "Epoch 76/100 - Loss: 0.2294, Accuracy: 0.6429\n",
      "Epoch 77/100 - Loss: 0.2293, Accuracy: 0.6429\n",
      "Epoch 78/100 - Loss: 0.2293, Accuracy: 0.6429\n",
      "Epoch 79/100 - Loss: 0.2293, Accuracy: 0.6429\n",
      "Epoch 80/100 - Loss: 0.2292, Accuracy: 0.6429\n",
      "Epoch 81/100 - Loss: 0.2292, Accuracy: 0.6429\n",
      "Epoch 82/100 - Loss: 0.2291, Accuracy: 0.6429\n",
      "Epoch 83/100 - Loss: 0.2291, Accuracy: 0.6429\n",
      "Epoch 84/100 - Loss: 0.2290, Accuracy: 0.6429\n",
      "Epoch 85/100 - Loss: 0.2290, Accuracy: 0.6429\n",
      "Epoch 86/100 - Loss: 0.2289, Accuracy: 0.6429\n",
      "Epoch 87/100 - Loss: 0.2289, Accuracy: 0.6429\n",
      "Epoch 88/100 - Loss: 0.2288, Accuracy: 0.6429\n",
      "Epoch 89/100 - Loss: 0.2288, Accuracy: 0.6429\n",
      "Epoch 90/100 - Loss: 0.2287, Accuracy: 0.6429\n",
      "Epoch 91/100 - Loss: 0.2287, Accuracy: 0.6429\n",
      "Epoch 92/100 - Loss: 0.2286, Accuracy: 0.6429\n",
      "Epoch 93/100 - Loss: 0.2286, Accuracy: 0.6429\n",
      "Epoch 94/100 - Loss: 0.2285, Accuracy: 0.6429\n",
      "Epoch 95/100 - Loss: 0.2285, Accuracy: 0.6429\n",
      "Epoch 96/100 - Loss: 0.2284, Accuracy: 0.6429\n",
      "Epoch 97/100 - Loss: 0.2284, Accuracy: 0.6429\n",
      "Epoch 98/100 - Loss: 0.2283, Accuracy: 0.6429\n",
      "Epoch 99/100 - Loss: 0.2283, Accuracy: 0.6429\n",
      "Epoch 100/100 - Loss: 0.2282, Accuracy: 0.6429\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('weather.nominal.csv')\n",
    "\n",
    "# Preprocess the data: encode categorical variables\n",
    "data['outlook'] = data['outlook'].map({'sunny': 0, 'overcast': 1, 'rainy': 2})\n",
    "data['temperature'] = data['temperature'].map({'hot': 0, 'mild': 1, 'cool': 2})\n",
    "data['humidity'] = data['humidity'].map({'high': 0, 'normal': 1})\n",
    "data['windy'] = data['windy'].map({False: 0, True: 1})\n",
    "data['play'] = data['play'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = data.iloc[:, :-1].values  # All columns except the last one\n",
    "y = data.iloc[:, -1].values  # The last column as the target label\n",
    "\n",
    "# Initialize the MLP with 4 inputs, 3 hidden neurons, and 1 output\n",
    "mlp = MLP(n_inputs=4, n_hidden=3, n_outputs=1, learning_rate=0.1, epochs=100)\n",
    "\n",
    "# Train the MLP\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1393d-2026-4046-a8b6-101cdda51f13",
   "metadata": {},
   "source": [
    "Once trained, the model is tested on a new example. A sample weather condition with specific values (e.g., sunny for outlook, mild for temperature, high for humidity, and false for windy) is encoded into a format compatible with the model. The predict function is then called with this input, and the MLP outputs its recommendation on whether to play tennis under these conditions. The result, displayed as either \"Yes\" or \"No,\" offers a user-friendly interpretation of the model's assessment based on the weather parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4039824-4aaf-4678-9fb4-bf08af3a4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play tennis with conditions [0 1 0 0]? Yes\n"
     ]
    }
   ],
   "source": [
    "# Test with a new example (outlook='sunny', temperature='mild', humidity='high', windy='false')\n",
    "new_example = np.array([0, 1, 0, 0])  # Encoded as per the mappings above\n",
    "result = mlp.predict(new_example)\n",
    "\n",
    "# Print the prediction result\n",
    "print(f\"Play tennis with conditions {new_example}? {'Yes' if result == 1 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4c764-e84e-4fa7-b128-d4a3010fbca4",
   "metadata": {},
   "source": [
    "## MLP using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e0d5f86-d4da-4fb9-b4fc-9680c6dd9567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity  Wind\n",
      "0         2           85        85     2\n",
      "1         2           80        90     2\n",
      "2         0           83        86     0\n",
      "3         1           70        96     1\n",
      "4         1           68        80     1\n",
      "5         1           65        70     1\n",
      "6         0           64        65     0\n",
      "7         2           72        95     2\n",
      "8         2           69        70     2\n",
      "9         1           75        80     1\n",
      "10        2           75        70     2\n",
      "11        0           72        90     0\n",
      "12        0           81        75     0\n",
      "13        1           71        91     1\n",
      "     Play\n",
      "0   False\n",
      "1   False\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "5   False\n",
      "6    True\n",
      "7   False\n",
      "8    True\n",
      "9    True\n",
      "10   True\n",
      "11   True\n",
      "12   True\n",
      "13  False\n"
     ]
    }
   ],
   "source": [
    "# from previous example\n",
    "print(X_train_num)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68099592-f3eb-4c88-8f04-5b30456c0548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(3,),\n",
       "              learning_rate_init=0.1, max_iter=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(3,),\n",
       "              learning_rate_init=0.1, max_iter=100, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(3,),\n",
       "              learning_rate_init=0.1, max_iter=100, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the MLPClassifier with similar parameters to the custom MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', learning_rate_init=0.1, max_iter=100, random_state=42)\n",
    "\n",
    "# Train the MLP on the training data\n",
    "mlp.fit(X_train_num.values, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af0373ab-0b76-4360-86e7-5cb2cb31c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should play tennis with conditions [0, 1, 0, 0]? Yes\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a new example (e.g., outlook='sunny', temperature='mild', humidity='high', windy=False)\n",
    "new_example = [[0, 1, 0, 0]]  # Encoded as per preprocessing\n",
    "result = mlp.predict(new_example)\n",
    "\n",
    "# Display the prediction result\n",
    "print(f\"Should play tennis with conditions {new_example[0]}? {'Yes' if result[0] == 1 else 'No'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
