{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42dadf4-391f-4726-b6bf-68c840172524",
   "metadata": {},
   "source": [
    "# Notebook ICD - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68613b4-d825-4e57-83c9-786266168cf7",
   "metadata": {},
   "source": [
    "## From scratch to scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64170fe5-aabb-4476-95a1-6e749e1a5905",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050516b5-c503-4d42-ad87-026a8fe4eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6984a-94e9-4f79-b803-5a31e75ced74",
   "metadata": {},
   "source": [
    "Load the dataset and separate input and Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f6562-fe80-424f-87e8-eb3f6f87233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_for_lr.csv')\n",
    " \n",
    "# Drop the missing values\n",
    "data = data.dropna()\n",
    " \n",
    "# training dataset and labels\n",
    "train_input = np.array(data.x[0:500]).reshape(500,1)\n",
    "train_output  = np.array(data.y[0:500]).reshape(500,1)\n",
    " \n",
    "# valid dataset and labels\n",
    "test_input = np.array(data.x[500:700]).reshape(199,1)\n",
    "test_output  = np.array(data.y[500:700]).reshape(199,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75bb57-9902-431f-bd0f-96dce6c68d91",
   "metadata": {},
   "source": [
    "Build the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36bc0a-00e8-4273-9386-aa695ebef0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\tdef __init__(self):\n",
    "\t\tself.parameters = {}\n",
    "\t\n",
    "\tdef forward_propagation(self, train_input):\n",
    "\t\tm = self.parameters['m']\n",
    "\t\tc = self.parameters['c']\n",
    "\t\tpredictions = np.multiply(m, train_input) + c\n",
    "\t\treturn predictions\n",
    "\n",
    "\tdef cost_function(self, predictions, train_output):\n",
    "\t\tcost = np.mean((train_output - predictions) ** 2)\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef backward_propagation(self, train_input, train_output, predictions):\n",
    "\t\tderivatives = {}\n",
    "\t\tdf = (train_output - predictions) * -1\n",
    "\t\tdm = np.mean(np.multiply(train_input, df))\n",
    "\t\tdc = np.mean(df)\n",
    "\t\tderivatives['dm'] = dm\n",
    "\t\tderivatives['dc'] = dc\n",
    "\t\treturn derivatives\n",
    "\n",
    "\tdef update_parameters(self, derivatives, learning_rate):\n",
    "\t\tself.parameters['m'] = self.parameters['m'] - learning_rate * derivatives['dm']\n",
    "\t\tself.parameters['c'] = self.parameters['c'] - learning_rate * derivatives['dc']\n",
    "\n",
    "\tdef train(self, train_input, train_output, learning_rate, iters):\n",
    "\t\t#initialize random parameters\n",
    "\t\tself.parameters['m'] = np.random.uniform(0,1) * -1\n",
    "\t\tself.parameters['c'] = np.random.uniform(0,1) * -1\n",
    "\t\t\n",
    "\t\t#initialize loss\n",
    "\t\tself.loss = []\n",
    "\t\t\n",
    "\t\t#iterate\n",
    "\t\tfor i in range(iters):\n",
    "\t\t\t#forward propagation\n",
    "\t\t\tpredictions = self.forward_propagation(train_input)\n",
    "\n",
    "\t\t\t#cost function\n",
    "\t\t\tcost = self.cost_function(predictions, train_output)\n",
    "\n",
    "\t\t\t#append loss and print\n",
    "\t\t\tself.loss.append(cost)\n",
    "\t\t\tprint(\"Iteration = {}, Loss = {}\".format(i+1, cost))\n",
    "\n",
    "\t\t\t#back propagation\n",
    "\t\t\tderivatives = self.backward_propagation(train_input, train_output, predictions)\n",
    "\n",
    "\t\t\t#update parameters\n",
    "\t\t\tself.update_parameters(derivatives, learning_rate)\n",
    "\n",
    "\t\treturn self.parameters, self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b6810-db19-4d2a-8f79-edd38df5b685",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825be235-95d5-4006-8339-c291a27d5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "linear_reg = LinearRegression()\n",
    "parameters, loss = linear_reg.train(train_input, train_output, 0.0001, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187b0c7-9583-4c48-84d0-71b7ccc292cf",
   "metadata": {},
   "source": [
    "Final Prediction and Plot the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324befe8-75c3-4bd4-a9cb-873a365373b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "print(parameters['m'])\n",
    "print(parameters['c'])\n",
    "y_pred = test_input*parameters['m'] + parameters['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff717ca8-e528-4dd7-915c-ded9698fd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regression line with actual data pointa\n",
    "plt.plot(test_input, test_output, '+', label='Actual values')\n",
    "plt.plot(test_input, y_pred, label='Predicted values')\n",
    "plt.xlabel('Test input')\n",
    "plt.ylabel('Test Output or Predicted output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb86fd-c43a-4c64-b4a9-bb4125ac6ead",
   "metadata": {},
   "source": [
    "### Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114af679-48e8-4e8e-a9e7-254650a676cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(train_input, train_output)\n",
    "print(reg.score(train_input, train_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b3450-731d-4983-9e1f-d5905d5d4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "y_pred = reg.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d426fc6-6297-4716-860c-f1aae683f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regression line with actual data pointa\n",
    "plt.plot(test_input, test_output, '+', label='Actual values')\n",
    "plt.plot(test_input, y_pred, label='Predicted values')\n",
    "plt.xlabel('Test input')\n",
    "plt.ylabel('Test Output or Predicted output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9c0a6-7a3c-4a58-a30b-38d56efab6fc",
   "metadata": {},
   "source": [
    "## Comparing algorithms for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e3196-c9fd-4333-9b5a-a183483806ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92556039-0550-4795-ada6-7de0259d3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset from Scikit-learn\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "data = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "data['target'] = diabetes.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee762a3-2aab-4681-800c-c775c983b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General dataset information\n",
    "data.info()\n",
    "\n",
    "# Descriptive statistics of the dataset\n",
    "data.describe()\n",
    "\n",
    "# Heatmap showing the correlation between features and the target variable\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation between features and diabetes progression')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships between target and some features\n",
    "sns.pairplot(data[['target', 'bmi', 's5', 'bp']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d013e-d6de-4360-afdd-c8d4daa56ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ae23e-721e-426c-8a0c-a6460974e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models and plot predictions\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f'Model: {model_name}')\n",
    "    print(f'Train R^2: {r2_score(y_train, y_pred_train):.4f}')\n",
    "    print(f'Test R^2: {r2_score(y_test, y_pred_test):.4f}')\n",
    "    print(f'Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f}')\n",
    "    print('-'*40)\n",
    "    \n",
    "    # Plot the predictions vs real values\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(y_test, y_pred_test, label='Predictions', color='blue')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'Actual vs Predicted - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf8956-7468-46ea-a068-8e2af3829878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "evaluate_model(linear_reg, X_train, X_test, y_train, y_test, 'Linear Regression')\n",
    "\n",
    "# 2. Ridge Regression\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "evaluate_model(ridge_reg, X_train, X_test, y_train, y_test, 'Ridge Regression')\n",
    "\n",
    "# 3. Lasso Regression\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "evaluate_model(lasso_reg, X_train, X_test, y_train, y_test, 'Lasso Regression')\n",
    "\n",
    "# 4. Random Forest Regression\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf_reg, X_train, X_test, y_train, y_test, 'Random Forest Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f877679-c59e-4349-863e-a1c56f868bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison based on R^2 score for training and testing sets\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Random Forest']\n",
    "train_scores = [\n",
    "    r2_score(y_train, linear_reg.predict(X_train)),\n",
    "    r2_score(y_train, ridge_reg.predict(X_train)),\n",
    "    r2_score(y_train, lasso_reg.predict(X_train)),\n",
    "    r2_score(y_train, rf_reg.predict(X_train))\n",
    "]\n",
    "test_scores = [\n",
    "    r2_score(y_test, linear_reg.predict(X_test)),\n",
    "    r2_score(y_test, ridge_reg.predict(X_test)),\n",
    "    r2_score(y_test, lasso_reg.predict(X_test)),\n",
    "    r2_score(y_test, rf_reg.predict(X_test))\n",
    "]\n",
    "\n",
    "# Bar plot comparing R^2 score for all models\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "index = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "bar1 = ax.bar(index, train_scores, bar_width, label='Train R^2')\n",
    "bar2 = ax.bar(index + bar_width, test_scores, bar_width, label='Test R^2')\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('R^2 Score')\n",
    "ax.set_title('Model performance comparison')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ebc71f-010d-4485-9ddf-025436fedb3c",
   "metadata": {},
   "source": [
    "## Other example, discrete target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2676b95-3169-4048-b4a1-1efc94346310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb8efd-5c00-4b9d-a7a7-676e8439dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine quality dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e61a76-4b4e-4d3a-a301-2f1ca2b1a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "# Descriptive statistics\n",
    "data.describe()\n",
    "\n",
    "# Correlation heatmap to explore relationships between features and the target\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation between features and wine quality')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships between important features and quality\n",
    "sns.pairplot(data[['quality', 'alcohol', 'sulphates', 'pH', 'residual sugar']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4c8e4-4a1f-4bca-8d15-6d096ff2410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de9673-000c-4bba-9fe6-5fdb637df56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models and visualize results\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f'Model: {model_name}')\n",
    "    print(f'Train R^2: {r2_score(y_train, y_pred_train):.4f}')\n",
    "    print(f'Test R^2: {r2_score(y_test, y_pred_test):.4f}')\n",
    "    print(f'Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f}')\n",
    "    print('-'*40)\n",
    "    \n",
    "    # Plot the actual vs predicted values\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test, y_pred_test, label='Predictions', color='blue')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'Actual vs Predicted - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d4692-b46f-440a-a971-36a786578079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "evaluate_model(linear_reg, X_train, X_test, y_train, y_test, 'Linear Regression')\n",
    "\n",
    "# 2. Ridge Regression\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "evaluate_model(ridge_reg, X_train, X_test, y_train, y_test, 'Ridge Regression')\n",
    "\n",
    "# 3. Lasso Regression\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "evaluate_model(lasso_reg, X_train, X_test, y_train, y_test, 'Lasso Regression')\n",
    "\n",
    "# 4. Random Forest Regression\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf_reg, X_train, X_test, y_train, y_test, 'Random Forest Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a05d5-186f-449a-b156-12b2fa5109b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance based on R^2 scores for training and testing sets\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Random Forest']\n",
    "train_scores = [\n",
    "    r2_score(y_train, linear_reg.predict(X_train)),\n",
    "    r2_score(y_train, ridge_reg.predict(X_train)),\n",
    "    r2_score(y_train, lasso_reg.predict(X_train)),\n",
    "    r2_score(y_train, rf_reg.predict(X_train))\n",
    "]\n",
    "test_scores = [\n",
    "    r2_score(y_test, linear_reg.predict(X_test)),\n",
    "    r2_score(y_test, ridge_reg.predict(X_test)),\n",
    "    r2_score(y_test, lasso_reg.predict(X_test)),\n",
    "    r2_score(y_test, rf_reg.predict(X_test))\n",
    "]\n",
    "\n",
    "# Bar plot comparing R^2 score for all models\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "index = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "bar1 = ax.bar(index, train_scores, bar_width, label='Train R^2')\n",
    "bar2 = ax.bar(index + bar_width, test_scores, bar_width, label='Test R^2')\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('R^2 Score')\n",
    "ax.set_title('Model performance comparison')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb4b9a-c1d1-4e5f-aa02-b6a9a82cc074",
   "metadata": {},
   "source": [
    "## Linear Regression vs. Multivariate Regression\n",
    "\n",
    "Difference between **Linear Regression** and **Multivariate Regression** using the **Wine Quality** dataset. Both types of regression are widely used for predictive modeling but differ in the number of predictors (features) used.\n",
    "\n",
    "### Key Differences:\n",
    "- **Linear Regression**: Models the relationship between a single independent variable and the dependent variable.\n",
    "- **Multivariate Regression**: Models the relationship between multiple independent variables and the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d6fd1-d05f-4496-9075-c89ea1121d62",
   "metadata": {},
   "source": [
    "# Linear Regression (Univariate)\n",
    "\n",
    "Linear Regression is a simple model where only one feature (independent variable) is used to predict a single target (dependent variable). The relationship is represented by a straight line and assumes a linear relationship between the feature and the target.\n",
    "\n",
    "For example, we can use **alcohol content** to predict the wine quality. The formula for Linear Regression is:\n",
    "\n",
    "\\[\n",
    "\\text{quality} = \\beta_0 + \\beta_1 \\times \\text{alcohol}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\beta_0 \\) is the intercept (where the line crosses the y-axis).\n",
    "- \\( \\beta_1 \\) is the coefficient (or weight) for the alcohol feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ba8cb-b259-40fd-aa99-99433c45c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code: Linear Regression with one feature (alcohol)\n",
    "X_uni = data[['alcohol']]\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_uni, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "print(f'R^2: {r2_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd8e38-48c0-4942-9db6-5214d74eed10",
   "metadata": {},
   "source": [
    "### Multivariate Regression\n",
    "\n",
    "In Multivariate Regression, we predict the target variable using multiple features instead of just one. This helps capture the complex relationships between multiple factors that influence the outcome. The formula for Multivariate Regression is:\n",
    "\n",
    "\\[\n",
    "\\text{quality} = \\beta_0 + \\beta_1 \\times \\text{alcohol} + \\beta_2 \\times \\text{sulphates} + \\dots + \\beta_n \\times \\text{feature}_n\n",
    "\\]\n",
    "\n",
    "Each feature \\( \\text{feature}_n \\) contributes to the prediction, with corresponding coefficients \\( \\beta_n \\) that represent the importance of each feature in determining the target value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08244614-ce37-4a53-a60b-a2ee96937cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code: Multivariate Regression with multiple features\n",
    "X_multi = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "print(f'R^2: {r2_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41bc89-21c8-4b74-91ab-6f99559b1199",
   "metadata": {},
   "source": [
    "### Visual Representation of Linear vs. Multivariate Regression\n",
    "\n",
    "- **Linear Regression**: The relationship between the predictor and the target is represented as a straight line in 2D space.\n",
    "- **Multivariate Regression**: The relationship is modeled in multi-dimensional space, but we cannot visualize it in 2D. Instead, we can think of it as a hyperplane in n-dimensional space (where \\( n \\) is the number of features).\n",
    "\n",
    "In practice, Multivariate Regression often leads to better predictions when multiple factors contribute to the outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db8878-8615-419e-b044-d37622c57c65",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The key difference between **Linear Regression** and **Multivariate Regression** lies in the number of features used:\n",
    "- **Linear Regression** involves just one feature to predict the target.\n",
    "- **Multivariate Regression** uses multiple features to predict the target, which generally improves the prediction accuracy.\n",
    "\n",
    "Multivariate Regression is especially useful in real-world datasets where several factors influence the outcome, as in the case of wine quality, where many physicochemical properties affect the final quality rating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
