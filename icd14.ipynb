{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a1fd84-04c7-4025-a50b-150a95b1e152",
   "metadata": {},
   "source": [
    "# Notebook ICD - 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517e961-c76e-4bf5-a115-7f816df754b9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd230f6-f7f7-4476-9510-de08a10ad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20dd22c-ddb6-4e49-a0c0-6e36d6465441",
   "metadata": {},
   "source": [
    "## Naive Bayes from scratch\n",
    "\n",
    "This section implements the NaiveBayesClassifier class that includes two main methods: fit and predict. \n",
    "\n",
    "The __init__ method initializes the data structures that will store the a priori probabilities of each class (self.class_priors), as well as the conditional probabilities for each attribute given a class (self.likelihoods). \n",
    "\n",
    "The **fit** method takes care of calculating the a priori probabilities of the classes from the observed frequencies in the training data and then calculates the likelihoods (conditional probabilities) by applying Laplace smoothing to avoid zero probability values when an attribute value has not been observed. \n",
    "\n",
    "Finally, the **predict** method takes test instances, calculates the posterior probabilities for each class, and assigns the class with the highest probability to each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6638611f-53b0-4819-8a26-690826a65663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}  # Prior probabilities of the classes\n",
    "        self.likelihoods = {}   # Conditional probabilities (likelihoods)\n",
    "        self.classes = None     # Unique classes in the dataset\n",
    "        self.features = None    # Features (attributes)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Get the unique classes and features (attributes)\n",
    "        self.classes = np.unique(y)\n",
    "        self.features = X.columns\n",
    "        total_samples = len(y)  # Total number of training instances\n",
    "        \n",
    "        # Estimate prior probabilities (relative frequency of each class)\n",
    "        class_counts = y.value_counts().to_dict()\n",
    "        self.class_priors = {cls: (class_counts[cls] / total_samples) for cls in self.classes}\n",
    "        \n",
    "        # Initialize conditional probabilities (likelihoods)\n",
    "        self.likelihoods = {cls: {} for cls in self.classes}\n",
    "        \n",
    "        # Calculate the likelihoods (conditional probabilities) for each feature\n",
    "        for cls in self.classes:\n",
    "            X_cls = X[y == cls]  # Filter instances where the class is 'cls'\n",
    "            total_cls_samples = len(X_cls)  # Number of instances per class\n",
    "            \n",
    "            # Calculate the likelihoods for each attribute and attribute value\n",
    "            for feature in self.features:\n",
    "                feature_counts = X_cls[feature].value_counts().to_dict()  # Frequency of each attribute value\n",
    "                total_feature_values = len(X[feature].unique())  # Total number of possible attribute values\n",
    "                \n",
    "                # Apply Laplace smoothing and calculate the likelihoods\n",
    "                self.likelihoods[cls][feature] = {\n",
    "                    value: (feature_counts.get(value, 0) + 1) / (total_cls_samples + total_feature_values)\n",
    "                    for value in X[feature].unique()\n",
    "                }\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Iterate over each test instance\n",
    "        for _, x in X_test.iterrows():\n",
    "            class_probabilities = {}  # Store the posterior probabilities for each class\n",
    "            \n",
    "            # Calculate the posterior probability for each class\n",
    "            for cls in self.classes:\n",
    "                # Initialize with the prior probability of the class\n",
    "                prob = self.class_priors[cls]\n",
    "                \n",
    "                # Multiply by the likelihoods (conditional probabilities) of each feature\n",
    "                for feature in self.features:\n",
    "                    value = x[feature]\n",
    "                    prob *= self.likelihoods[cls][feature].get(value, 1 / (len(self.likelihoods[cls][feature]) + len(self.features)))\n",
    "                \n",
    "                # Store the calculated probability for the class\n",
    "                class_probabilities[cls] = prob\n",
    "            \n",
    "            # Select the class with the highest posterior probability\n",
    "            predicted_class = max(class_probabilities, key=class_probabilities.get)\n",
    "            results.append(predicted_class)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129d3f7-f099-4c31-bbbb-257afc13d537",
   "metadata": {},
   "source": [
    "### Implementation example\n",
    "\n",
    "The 'Play Tennis' dataset will be imported in order to build a Naive Bayes classifier to predict whether tennis will be played or not as a function of weather conditions such as temperature, humidity and wind. The 14 available instances will serve as a training basis for the model, while a new instance, not included in the training, will be used to evaluate its performance and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2be7aad-f856-4055-bf55-369730c7d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the instance {'outlook': 'sunny', 'temperature': 'cool', 'humidity': 'high', 'windy': True}: no\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('weather.nominal.csv')\n",
    "\n",
    "# Define X (features) and y (label)\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]  # Last column (label)\n",
    "\n",
    "# Train the classifier using the Naive Bayes algorithm with the original column names\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X, y)\n",
    "\n",
    "# Create the instance to test: sunny, hot, normal, TRUE\n",
    "test_instance = pd.DataFrame([{\n",
    "    'outlook': 'sunny',\n",
    "    'temperature': 'cool',\n",
    "    'humidity': 'high',\n",
    "    'windy': True\n",
    "}])\n",
    "\n",
    "# Make the prediction\n",
    "prediction = nb_classifier.predict(test_instance)\n",
    "print(f\"Prediction for the instance {test_instance.iloc[0].to_dict()}: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ab68f-6436-4bf0-a402-9b13ddde48ac",
   "metadata": {},
   "source": [
    "## Scikit-learn implementation\n",
    "\n",
    "The Naive Bayes algorithm is a simple and efficient probabilistic classifier that assumes conditional independence between features. While this assumption may not always hold in real-world data, Naive Bayes often performs remarkably well in many applications.\n",
    "\n",
    "**Naive Bayes Classifier**\n",
    "\n",
    "The Naive Bayes algorithm is built on Bayes' Theorem, which is expressed as:\n",
    "\n",
    "\\[\n",
    "P(C|X) = \\frac{P(X|C)P(C)}{P(X)}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\(P(C|X)\\) represents the posterior probability of class \\(C\\) given the data \\(X\\),\n",
    "- \\(P(X|C)\\) is the likelihood of the data given class \\(C\\),\n",
    "- \\(P(C)\\) is the prior probability of class \\(C\\),\n",
    "- \\(P(X)\\) is the probability of the data (which is constant for all classes and can be ignored for classification purposes).\n",
    "\n",
    "**Gaussian Naive Bayes**\n",
    "\n",
    "In the case of Gaussian Naive Bayes (GaussianNB), the algorithm assumes that the features follow a Gaussian (normal) distribution. The likelihood of a feature \\(x_i\\) given a class \\(C_k\\) is calculated using the probability density function of the Gaussian distribution:\n",
    "\n",
    "\\[\n",
    "P(x_i | C_k) = \\frac{1}{\\sqrt{2\\pi \\sigma_k^2}} \\exp\\left(-\\frac{(x_i - \\mu_k)^2}{2\\sigma_k^2}\\right)\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\mu_k \\) denotes the mean of feature \\(x_i\\) for class \\(C_k\\),\n",
    "- \\( \\sigma_k^2 \\) is the variance of feature \\(x_i\\) for class \\(C_k\\),\n",
    "- \\( x_i \\) represents the value of the feature for the given instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdecfc-8804-431c-a499-ae1c3e628c2b",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebc00df-3b04-4f55-aa0e-2bd427894639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab3690-420e-4ac4-bcb7-5db3fe4dce82",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3e6290-3f3a-4618-a827-2948f36ef6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'weather.numeric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1f8b8-f1dd-4a8b-acf4-c6370dc26ca7",
   "metadata": {},
   "source": [
    "Show dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9d98b6-cfb0-4f7f-8484-63e59c8e5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   Outlook  Temperature  Humidity    Wind   Play\n",
      "0     1     sunny           85        85    weak  False\n",
      "1     2     sunny           80        90  strong  False\n",
      "2     3  overcast           83        86    weak   True\n",
      "3     4      rain           70        96    weak   True\n",
      "4     5      rain           68        80    weak   True\n",
      "5     6      rain           65        70  strong  False\n",
      "6     7  overcast           64        65  strong   True\n",
      "7     8     sunny           72        95    weak  False\n",
      "8     9     sunny           69        70    weak   True\n",
      "9    10      rain           75        80    weak   True\n",
      "10   11     sunny           75        70  strong   True\n",
      "11   12  overcast           72        90  strong   True\n",
      "12   13  overcast           81        75    weak   True\n",
      "13   14      rain           71        91  strong  False\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1116a5d-0c02-4315-bbe6-7004d0f36755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity    Wind\n",
      "0     sunny           85        85    weak\n",
      "1     sunny           80        90  strong\n",
      "2  overcast           83        86    weak\n",
      "3      rain           70        96    weak\n",
      "4      rain           68        80    weak\n",
      "    Play\n",
      "0  False\n",
      "1  False\n",
      "2   True\n",
      "3   True\n",
      "4   True\n"
     ]
    }
   ],
   "source": [
    "# defining the dependent and independent variables\n",
    "X_train = df[['Outlook', 'Temperature', 'Humidity', 'Wind']]\n",
    "y_train = df[['Play']]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8d45c-cde8-43bb-a452-6d144ede0ef3",
   "metadata": {},
   "source": [
    "### From categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019663c8-3683-4c65-9884-b0d6119725f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain']\n",
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n",
      "['weak', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'strong']\n",
      "[1 0 1 1 1 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "outlook = X_train.iloc[:,0]\n",
    "outlook_enc = encoder.fit_transform(outlook)\n",
    "print(outlook.tolist())\n",
    "print(outlook_enc)\n",
    "\n",
    "wind = X_train.iloc[:,3]\n",
    "wind_enc = encoder.fit_transform(wind)\n",
    "print(wind.tolist())\n",
    "print(wind_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c1b430-f87d-4620-9d93-39efcbe24b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity  Wind\n",
      "0         2           85        85     2\n",
      "1         2           80        90     2\n",
      "2         0           83        86     0\n",
      "3         1           70        96     1\n",
      "4         1           68        80     1\n",
      "5         1           65        70     1\n",
      "6         0           64        65     0\n",
      "7         2           72        95     2\n",
      "8         2           69        70     2\n",
      "9         1           75        80     1\n",
      "10        2           75        70     2\n",
      "11        0           72        90     0\n",
      "12        0           81        75     0\n",
      "13        1           71        91     1\n"
     ]
    }
   ],
   "source": [
    "df_outlook = pd.DataFrame(outlook_enc, columns = ['Outlook'])\n",
    "df_wind = pd.DataFrame(outlook_enc, columns = ['Wind'])\n",
    "X_train_num = pd.concat([df_outlook, X_train.iloc[:,1], X_train.iloc[:,2], df_wind], axis=1)\n",
    "print(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daff3dc-d455-45b2-ab70-5f7a5320d9e0",
   "metadata": {},
   "source": [
    "### Generaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406a85d-f788-4f70-820a-df9036629e17",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes. GaussianNB implements the Gaussian Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6b3869-1a3e-4db9-a107-82514c342577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB().fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea696819-939d-417d-ab64-1f90101ea5be",
   "metadata": {},
   "source": [
    "### Evaluando modelo con nueva instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8019757e-19db-4192-b239-26d2aa9c3cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Outlook  Temperature  Humidity  Wind\n",
      "0        2           60        65     1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sunny:2, hot:85, normal:65, strong:0 \n",
    "new_example = [[2, 60, 65, 1]]\n",
    "X_test = pd.DataFrame(new_example, columns = ['Outlook', 'Temperature', 'Humidity', 'Wind'])\n",
    "print(X_test)\n",
    "clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
